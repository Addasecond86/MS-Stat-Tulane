@article{Cortes1995,
  abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition. © 1995, Kluwer Academic Publishers. All rights reserved.},
  author   = {Corinna Cortes and Vladimir Vapnik},
  doi      = {10.1023/A:1022627411411},
  issn     = {15730565},
  issue    = {3},
  journal  = {Machine Learning},
  title    = {Support-Vector Networks},
  volume   = {20},
  year     = {1995}
}
@article{Berkson1944,
  author  = {Joseph Berkson},
  doi     = {10.1080/01621459.1944.10500699},
  issn    = {1537274X},
  issue   = {227},
  journal = {Journal of the American Statistical Association},
  title   = {Application of the Logistic Function to Bio-Assay},
  volume  = {39},
  year    = {1944}
}

@article{Akaike1974,
  abstract = {The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximurn likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AlC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples. © 1974, IEEE. All rights reserved.},
  author   = {Hirotugu Akaike},
  doi      = {10.1109/TAC.1974.1100705},
  issn     = {15582523},
  issue    = {6},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {A New Look at the Statistical Model Identification},
  volume   = {19},
  year     = {1974}
}

@article{Pearson1901,
  abstract = {AbstractDownload full textRelated var addthis_config = \{ ui_cobrand: "Taylor &amp; Francis Online", services_compact: "citeulike,netvibes,twitter,technorati,delicious,linkedin,facebook,stumbleupon,digg,google,more", pubid: "ra-4dff56cd6bb1830b" \}; Add to shortlist Link Permalink http://dx.doi.org/10.1080/14786440109462720 Download Citation Recommend to: A friend},
  author   = {Karl Pearson},
  doi      = {10.1080/14786440109462720},
  issn     = {1941-5982},
  issue    = {11},
  journal  = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  title    = { LIII. On lines and planes of closest fit to systems of points in space },
  volume   = {2},
  year     = {1901}
}

@article{Lu2020,
  abstract = {The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. There are many empirical and heuristic explanations of why ReLU neurons die. However, little is known about its theoretical analysis. In this paper, we rigorously prove that a deep ReLU network will eventually die in probability as the depth goes to infinite. Several methods have been proposed to alleviate the dying ReLU. Perhaps, one of the simplest treatments is to modify the initialization procedure. One common way of initializing weights and biases uses symmetric probability distributions, which suffers from the dying ReLU. We thus propose a new initialization procedure, namely, a randomized asymmetric initialization. We show that the new initialization can effectively prevent the dying ReLU. All parameters required for the new initialization are theoretically designed. Numerical examples are provided to demonstrate the effectiveness of the new initialization procedure.},
  author   = {Lu Lu and Yeonjong Shin and Yanhui Su and George Em Karniadakis},
  doi      = {10.4208/CICP.OA-2020-0165},
  issn     = {19917120},
  issue    = {5},
  journal  = {Communications in Computational Physics},
  title    = {Dying ReLU and initialization: Theory and numerical examples},
  volume   = {28},
  year     = {2020}
}

@article{goodfellow20166,
  title     = {6.5 back-propagation and other differentiation algorithms},
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  journal   = {Deep learning},
  pages     = {200--220},
  year      = {2016},
  publisher = {MIT press Cambridge, MA, USA}
}