\documentclass[11pt, a4paper, jou]{apa7}
\setlength{\headheight}{14pt}
\usepackage[style=numeric, sorting=none]{biblatex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{float}

\usepackage{longtable}

\addbibresource{Ref.bib}

\leftheader{ZEHAO WANG}

\linespread{1.5}
\title{Will it rain tomorrow? --- Course Report on Weather Prediction}
\shorttitle{BIOS-7650 COURSE PROJECT}
\author{Zehao Wang}
\authorsaffiliations{Master student in Statistics, Department of Mathematics}
\course{BIOS-7650 Statistical Learning in Data Science}
\professor{Dr.\ Li. }
\duedate{\today}
\abstract{Whether it rains or not has the most direct impact on our daily life, therefore, the weather forecast is particularly important for us. The traditional approach to predict raining is to use computers combined with satellite cloud maps to solve a set of dynamical system equations\cite{teague2017evolution}. However, since the 21st century, the statistical learning approach has gradually become mainstream. Therefore, in this report, we try to use statistical learning methods (logistic regression, SVM and neural networks) to predict the weather. 
On the \href{https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package}{\emph{Rain in Australia}} dataset, we finally achieved an accuracy of $80.5\%$ by using logistic regression. This result is lower than the current weather forecast accuracy (\href{https://www.forecastadvisor.com/Louisiana/NewOrleans/70112/}{forecasting accuracy in New Orleans}). And the code can be found in \href{https://github.com/Addasecond86/MS-Stat-Tulane/blob/main/Stat_Learning_in_Data_Analysis/Project/Code/Project_code.ipynb}{Github}. 
}
\begin{document}
\maketitle
\section{Methods}
The dataset we use is the \href{https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package}{\emph{Rain in Australia}} on Kaggle. It contains different weather indicators (e.g. temperature, humidity, wind direction, etc.) and whether it rained the next day for various regions of Australia for almost a decade, from October 2007 to June 2017. Before we make a prediction, the first thing we need to do is to clean the data. I dropped the subjects that contains \emph{NA} value in any variables. And then, I also transform the categorical variables into dummy variables. After finishing data cleaning, as shown in Table~(\ref{tab:day_imbalance}), we can find that the distribution of the data is imbalanced. The number of days that it rained is only about $22\%$ of the total number of days. This means that if we assume that all weather is not going to rain, then we also have an accuracy of $77.9741\%$. Therefore, we need to use some methods to deal with the imbalanced data. 
\begin{table}[h]
    \centering
    \caption{Distribution of the number of days with and without rain after data cleaning.}
    \label{tab:day_imbalance}
    \begin{tabular}{lll}
    \hline
    Weather     & \# Days & Percentage \\ \hline
    Not raining & 43993   & 0.779741   \\
    Raining     & 12427   & 0.220259   \\ \hline
    \end{tabular}
\end{table}

Since we have a larger amount of data, we can use undersampling, i.e., discard some data randomly in the class with more data, so that the number of data in the two classes is equal. The results after undersampling are shown in Table (\ref{tab:day_undersampling}). 
\begin{table}[h]
    \centering
    \caption{Distribution of the number of days after undersampling.}
    \label{tab:day_undersampling}
    \begin{tabular}{lll}
    \hline
    Weather     & \# Days & Percentage \\ \hline
    Not raining & 12427   & 0.5   \\
    Raining     & 12427   & 0.5   \\ \hline
    \end{tabular}
\end{table}
\subsection{Logistic Regression}
    Logistic regression\cite{Berkson1944} is widely used in binary classification problems. Assume $p$ is the probability of rain tomorrow, then, for logistic regression, we have
    \begin{equation}
        \frac{p}{1-p}=\exp\left(\beta_0+\sum_{i=1}^{n}\beta_i x_i\right). 
    \end{equation}
    And we can estimate the coefficients $\beta_i$ by maximum likelihood estimation. 

    We first use all the variables except the date and interactions as predictor variables to predict whether it will rain tomorrow. Further, we use stepwise to explore whether the model can be further optimized. Akaike information criterion (AIC)\cite{Akaike1974} was used to see if any of the variables can be eliminated. AIC is a measure of the relative quality of statistical models for a given set of data. It is defined as following: 
    \begin{equation}
        \label{eq:AIC}
        {AIC} \,=\,2k-2\ln({\hat {L}}). 
    \end{equation}
    And $k$ is the number of estimated parameters in the model, $\hat{L}$ is the maximized value of the likelihood function for the model. So, the preferred model is the one with the minimum AIC value. 

    We also used Principal Component Analysis (PCA)\cite{Pearson1901} to extract features from the data. PCA is a method of reducing the dimensionality of data by transformation, which assumes that variables with higher variance carry more information. By reducing the dimensionality, we expect a significant increase in the classification accuracy. And because the absolute values of the variables are too different from each other, we should first transform the variables by (\ref{eq:trans}) to map them all to $[0,1]$. 
    \begin{equation}
        \label{eq:trans}
        X_{new} = \frac{X - X_{\min}}{X_{\max}- X_{\min}}. 
    \end{equation}
\subsection{SVM}
    Support Vector Machine (SVM) is a better method than logistic regression, it tries to maximize the margin between two different classes of data points. So it will have much lower risk on the test set. The optimization objectives of SVM are as following:  
    \begin{equation}
        \min_{|w|}\ y_{i}(\mathbf {w} ^{\mathsf {T}}\mathbf {x} _{i}-b)\geq 1,\ i=1, \cdots, n
    \end{equation}
    When the data is not linearly separable, we can add soft margins to it. The optimization goal then becomes the following: 
    \begin{equation}
        \min_{|w|}\ \lambda |\mathbf {w}| ^{2}+{\frac {1}{n}}\sum _{i=1}^{n}\max \left(0,1-y_{i}(\mathbf {w} ^{\mathsf {T}}\mathbf {x} _{i}-b)\right). 
    \end{equation}
    After that, we can transform it into a dual problem and then estimate the parameters by gradient descent. 

    For nonlinear data sets, we can use the kernel trick to map the original data to the projection space. And in projection space, we can separate them using a linear hyperplane. By using different kernel functions, we can project them into different spaces. The common kernel functions are polynomial kernel functions and Gaussian kernel functions. 

\subsection{Neural Network}
    In the 21st century, network-based approaches are undoubtedly the mainstream of machine learning. Considering the complexity of the data, we only use a simple fully connected network with two hidden layers. Its structure is shown in Figure~(\ref{fig:nn}). In this network, the activation functions of both fully connected hidden layers are ReLU\cite{Lu2020}. It can solve the gradient disappearance or explosion problem in some extent. Also, Sigmoid is used as the activation function in the output layer. Therefore, the final output we get is an output in $(0,1)$, and we consider values greater than $0.5$ as $1$, otherwise as $0$. 

    The optimization algorithm for neural network parameters is Backpropagation\cite{goodfellow20166}. It uses the chain derivative rule to complete the update of the parameters. Since we are dealing with a binary classification problem, we use binary cross-entropy (\ref{eq:binary cross_entropy}) as the loss function. 
    \begin{equation}
        \label{eq:binary cross_entropy}
        L = -\frac{1}{n}\sum_{i=1}^{n}(y_i\ln(p_i)+(1-y_i)\ln(1-p_i))
    \end{equation}
    It can be seen that the more $p(y)$ matches with $y$, the closer the loss function is to $0$. On the contrary, it is infinite. 

\section{Results}

\subsection{Logistic Regression}
    Using $80\%$ data as training set and $20\%$ as test set, we first fitted a logistic regression model with the original data, which is imbalanced. The accuracy on test set and train set are $85.8029\%$ and $85.6323\%$. Figure~(\ref{fig:log_cm}) and Table~(\ref{tab:log_summary}) show test results. It can be seen that the model has a high accuracy and recall for rainy days. However, it has a low recall for non-rainy days. This means the model fitted with imbalanced data has no ability to predict a raining day. 
    
    Next, we using the undersampling data trained a logistic regression model. The accuracy on test set and train set are $80.5673\%$ and $80.5009\%$. Comparing these two models, we can see that although the overall accuracy of the model trained with undersampled data is lower, it has a higher recall for rainy days. This means that the model trained with undersampled data has better ability to predict rainy days. 

    Then, we start from the full model and use AIC as a criterion to see if any variables can be excluded. The last step of stepwise is shown in Table~(\ref{tab:model_selection_aic}). It shows that we can exclude the variable \emph{Evaporation}, \emph{MaxTemp}, \emph{Temp3pm} to get a better model. The accuracy of this model on the test set is $80.2253\%$, and this accuracy is slightly lower. 

\subsection{SVM}
    We used the same training and testing data on this method. Using SVM with linear kernel, the accuracy obtained on the test set is $80.0845\%$. And the training accuracy is $80.8027\%$. This result is basically same as the logistic regression, which indicate that some of subjects in our dataset are linearly inseparable. Its confusion matrix is shown in Figure~(\ref{fig:svm_cm}), and the accuracy and recall are shown in Table~(\ref{tab:svm_summary}). 

    The reason for no improvement in classification accuracy may be that the data itself is linearly inseparable. So we try to introduce two kernel functions (polynomial and Gaussian). The results are shown in Table~(\ref{tab:svm_kernel_summary}). However, based on the classification results, the accuracy of both methods on the test set are much lower. And they are almost in the same level with the model just directly predict every days as not raining. This is probably because these two kernel functions cannot separate the two classes of data. 

    However, in general, we do expect SVM perform better, so we tried to use PCA to extract features first, and then use the model to classify the data. Using PCA, we chose to retain $95\%$ of the information, and we reduced the original 115-dimensional data to 66 dimensions. The classification results on this data are shown in Table~(\ref{tab:svm_summary_pca}), (\ref{tab:svm_summary_poly_pca}), (\ref{tab:svm_summary_gaus_pca}). 

    After using PCA, the accuracy of these three methods basically did not change. This is probably because the data itself is linearly inseparable. So, the PCA method cannot extract features that can separate the two classes of data. 

\subsection{Neural Network}
We used the same training and testing data and mapped the data to $(0,1)$ and started training. First, the network was trained with $100$ Epochs. The loss of the model on the test set and the loss on the validation set during the training process are shown in Figure~(\ref{fig:nn_100}). It can be seen that, although the training loss keeps decreasing, the loss on the validation set stops decreasing after $40$ epochs and even starts to increase. This indicates that the overfitting starts after $40$ Epochs. So, we retrain a $40$ Epochs network. And the training process is shown as Figure~(\ref{fig:nn_40}). It can be seen from the figure that overfitting has not occurred. The performance of this network on the test set is shown in Figure~(\ref{fig:nn_cm}) and Table~(\ref{tab:nn_summary}). In the end, we obtained an accuracy of $80.3661\%$ on the test set. And This is the highest accuracy we have obtained so far.

\section{Discussion}

As you can see, we use three different approaches, but the results are basically the same, that is, we can only achieve an accuracy of over $80.5\%$ at most. This seems very frustrating, because the error rate is about $19\%$. This means that on average the prediction will be wrong one day out of a week. 

However, this is about the level of accuracy of current weather predictions. You can see the accuracy of the weather predictions for New Orleans last year on this \href{https://www.forecastadvisor.com/Louisiana/NewOrleans/70112/}{website}. As shown in Figure~(\ref{fig:weather_prediction_nola}), this website shows that the highest channel for 2021 weather prediction accuracy in the New Orleans area is just $84.92\%$. 

In addition, we can see that the accuracy and recall of the three models are higher for not raining weather than raining weather. This means that when the weather prediction says it will not rain, then it is very likely that it will not rain. But when the prediction says it will rain, then there is also a chance that it will not rain. Therefore, to avoid the second error case, which occurs more frequently, the weather forecast is now given in the form of rainfall probabilities. 

On the other hand, due to the interpretability of the logistic regression model, we can see which variable causes the most significant change in the probability of raining after mapping each variable to $[0,1]$. The first 10 coefficients with the largest absolute values are shown in Table~(\ref{tab:rank_coef}). From the table, we can see that the pressure at 3pm is negatively correlated with raining, while the wind speed and the humidity at 3pm are positively correlated with raining. 

Finally, for further improvement, the date variable could be added to turn our data into a time series. On this basis, it might be useful to consider adding periodic factors such as seasonality to the forecasting model. Also, interactions can be introduced in the logistic regression model. 

\printbibliography 
\clearpage
\appendix
\section{Figures and Tables}

\begin{figure}[p]
    \centering
    \caption{Confusion matrix for logistic regression models with imbalanced data on the test set. 0 means not raining and 1 means raining. }\label{fig:log_cm}
    \includegraphics[width=.45\textwidth]{figures/log_cm.eps}
\end{figure}

\begin{table}[p]
    \centering
    \caption{Classification results of logistic regression model with imbalanced data on the test set. }\label{tab:log_summary}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
        Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.88 & 0.95 & 0.91 & 8720 \\
    Raining      & 0.76 & 0.55 & 0.64 & 2564  \\
    accuracy     &      &      & 0.86 & 11284 \\
    macro avg    & 0.82 & 0.75 & 0.77 & 11284 \\
    weighted avg & 0.85 & 0.86 & 0.85 & 11284 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{figure}[p]
    \centering
    \caption{Confusion matrix for logistic regression models with undersampled data on the test set.}\label{fig:log_cm_undersampling}
    \includegraphics[width=.45\textwidth]{figures/log_cm_undersampling.eps}
\end{figure}

\begin{table}[p]
    \centering
    \caption{Classification results of logistic regression model with undersampled data on the test set. }\label{tab:log_undersampling_summary}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
        Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.80 & 0.80 & 0.80 & 2456 \\
    Raining      & 0.81 & 0.81 & 0.81 & 2515  \\
    accuracy     &      &      & 0.81 & 4971 \\
    macro avg    & 0.81 & 0.81 & 0.81 & 4971 \\
    weighted avg & 0.81 & 0.81 & 0.81 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{figure}[p]
    \centering
    \caption{Confusion matrix for SVM on the test set. }\label{fig:svm_cm}
    \includegraphics[width=.45\textwidth]{figures/svm_cm_undersampling.eps}
\end{figure}

\begin{table}[p]
    \centering
    \caption{Classification results of SVM on the test set. }\label{tab:svm_summary}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
        Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.79 & 0.81 & 0.80 & 2472 \\
    Raining      & 0.81 & 0.79 & 0.80 & 2499  \\
    accuracy     &      &      & 0.80 & 4971 \\
    macro avg    & 0.80 & 0.80 & 0.80 & 4971 \\
    weighted avg & 0.80 & 0.80 & 0.80 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{table}[p]
    \centering
    \caption{Classification results of SVM with polynomial and gaussian kernel function on the test set. }
    \label{tab:svm_kernel_summary}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.76 & 0.79 & 0.78 & 2472 \\
    Raining      & 0.79 & 0.76 & 0.77 & 2499  \\
    accuracy     &      &      & 0.78 & 4971 \\
    macro avg    & 0.78 & 0.78 & 0.78 & 4971 \\
    weighted avg & 0.78 & 0.78 & 0.78 & 4971 \\ \hline
    \end{tabular}%
    }
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.76 & 0.78 & 0.77 & 2472  \\
    Raining      & 0.78 & 0.76 & 0.77 & 2499  \\
    accuracy     &      &      & 0.77 & 4971 \\
    macro avg    & 0.78 & 0.77 & 0.77 & 4971 \\
    weighted avg & 0.78 & 0.77 & 0.77 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{table}[p]
    \centering
    \caption{Classification results of SVM using PCA on the test set. }\label{tab:svm_summary_pca}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.79 & 0.73 & 0.76 & 2472  \\
    Raining      & 0.75 & 0.81 & 0.78 & 2499  \\
    accuracy     &      &      & 0.77 & 4971 \\
    macro avg    & 0.78 & 0.77 & 0.77 & 4971 \\
    weighted avg & 0.78 & 0.77 & 0.77 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{table}[p]
    \centering
    \caption{Classification results of SVM using PCA and polynomial kernel function on the test set. }\label{tab:svm_summary_poly_pca}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.78 & 0.76 & 0.77 & 2472  \\
    Raining      & 0.77 & 0.79 & 0.78 & 2499  \\
    accuracy     &      &      & 0.77 & 4971 \\
    macro avg    & 0.78 & 0.77 & 0.77 & 4971 \\
    weighted avg & 0.78 & 0.77 & 0.77 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{table}[p]
    \centering
    \caption{Classification results of SVM using PCA and gaussian kernel function on the test set. }\label{tab:svm_summary_gaus_pca}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.80 & 0.76 & 0.78 & 2472  \\
    Raining      & 0.78 & 0.81 & 0.79 & 2499  \\
    accuracy     &      &      & 0.79 & 4971 \\
    macro avg    & 0.79 & 0.79 & 0.79 & 4971 \\
    weighted avg & 0.79 & 0.79 & 0.79 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{figure}[p]
    \centering
    \caption{Training process for 50 epochs. }\label{fig:nn_100}
    \includegraphics[width=.45\textwidth]{figures/error_100.eps}
\end{figure}

\begin{figure}[p]
    \centering
    \caption{Training process for 20 epochs. }\label{fig:nn_40}
    \includegraphics[width=.45\textwidth]{figures/error_40.eps}
\end{figure}


\begin{figure}[p]
    \centering
    \caption{Confusion matrix for neural network trained for 40 epochs. }\label{fig:nn_cm}
    \includegraphics[width=.45\textwidth]{figures/nn_cm.eps}
\end{figure}

\begin{table}[p]
    \centering
    \caption{Classification results of neural network on the test set. }\label{tab:nn_summary}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{rrrrr}
    \hline
    Model & precision & recall & f1-score & support \\ \hline
    Not Raining  & 0.81 & 0.79 & 0.80 & 2472  \\
    Raining      & 0.80 & 0.82 & 0.81 & 2499  \\
    accuracy     &      &      & 0.80 & 4971 \\
    macro avg    & 0.80 & 0.80 & 0.80 & 4971 \\
    weighted avg & 0.80 & 0.80 & 0.80 & 4971 \\ \hline
    \end{tabular}%
    }
\end{table}

\begin{figure}[p]
    \centering
    \caption{Structure of neural network we used. }\label{fig:nn}
    \includegraphics[width=.35\textwidth]{figures/Network_structure.png}
\end{figure}

\begin{table}[p]
    \centering
    \caption{Model selection for logistic regression with AIC as criterion. the model exclude Humidity9am has the smallest AIC. }
    \label{tab:model_selection_aic}
    \begin{tabular}{lll}
    \hline
                   & Deviance & AIC   \\ \hline
    None           & 20525    & 20695 \\
    +Evaporation   & 20523    & 20695 \\
    +MaxTemp       & 20524    & 20696 \\
    +Temp3pm       & 20524    & 20696 \\
    -Cloud9am      & 20528    & 20696 \\
    -MinTemp       & 20531    & 20699 \\
    -Humidity9am   & 20531    & 20699 \\
    -Rainfall      & 20532    & 20700 \\
    -WindSpeed9am  & 20534    & 20702 \\
    -WindGustDir   & 20563    & 20703 \\
    -Temp9am       & 20537    & 20705 \\
    -WindSpeed3pm  & 20551    & 20719 \\
    -WindDir3pm    & 20591    & 20731 \\
    -RainToday     & 20615    & 20783 \\
    -WindDir9am    & 20645    & 20785 \\
    -Cloud3pm      & 20696    & 20864 \\
    -Pressure9am   & 20698    & 20866 \\
    -Location      & 20796    & 20916 \\
    -Pressure3pm   & 20868    & 21036 \\
    -Sunshine      & 20891    & 21059 \\
    -WindGustSpeed & 21267    & 21435 \\
    -Humidity3pm   & 21715    & 21883 \\ \hline
    \end{tabular}
    \end{table}


\begin{figure}[p]
    \centering
    \caption{Weather prediction accuracy for New Orleans in 2021. The highest one has an accuracy of $84.92\%$. }\label{fig:weather_prediction_nola}
    \includegraphics[width=.55\textwidth]{figures/Weather2021.png}
\end{figure}

\begin{table}[p]
\centering
\caption{The first 10 variables with the largest absolute value of the coefficient. }
\label{tab:rank_coef}
\begin{tabular}{lrr}
    \hline
    Variables     & Coef       & AbsCoef    \\ \hline
    Pressure3pm   & -6.376243  & 6.37624304 \\
    WindGustSpeed & 6.015306   & 6.015306   \\
    Humidity3pm   & 5.30604568 & 5.30604568 \\
    Pressure9am   & 2.39249102 & 2.39249102 \\
    Sunshine      & -2.1990392 & 2.1990392  \\
    Rainfall      & 1.51833808 & 1.51833808 \\
    Cloud3pm      & 1.04841031 & 1.04841031 \\
    MinTemp       & -0.9993698 & 0.99936978 \\
    WindSpeed3pm  & -0.8875335 & 0.88753345 \\
    MaxTemp       & 0.77989505 & 0.77989505 \\ \hline
    \end{tabular}
\end{table}

\end{document}